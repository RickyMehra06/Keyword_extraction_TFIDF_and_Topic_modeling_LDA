{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a12cd832",
   "metadata": {},
   "source": [
    "## Keyword extraction using TFIDF and Topic modeling using LDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe8cf021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from gensim import models, corpora\n",
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e969e40b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>understand random forestthis article publish d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2 boost – combine weak learner strong learner ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model model 01 model 02 model 03 obtain bootst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>step involve random forest algorithm step 1 ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>important features random forest1 diversity- a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      processed_text\n",
       "0  understand random forestthis article publish d...\n",
       "1  2 boost – combine weak learner strong learner ...\n",
       "2  model model 01 model 02 model 03 obtain bootst...\n",
       "3  step involve random forest algorithm step 1 ra...\n",
       "4  important features random forest1 diversity- a..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"datasets/PDF_text_data.csv\")\n",
    "df.drop(['text'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e644cfaf",
   "metadata": {},
   "source": [
    "### Keyword extraction using TFIDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e24bf436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['understand',\n",
       "  'random',\n",
       "  'forestthis',\n",
       "  'article',\n",
       "  'publish',\n",
       "  'data',\n",
       "  'science',\n",
       "  'blogathonintroductionrandom',\n",
       "  'forest',\n",
       "  'supervised',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'algorithm',\n",
       "  'use',\n",
       "  'widely',\n",
       "  'classification',\n",
       "  'andregression',\n",
       "  'problem',\n",
       "  'build',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'different',\n",
       "  'sample',\n",
       "  'majority',\n",
       "  'vote',\n",
       "  'forclassification',\n",
       "  'average',\n",
       "  'case',\n",
       "  'regression',\n",
       "  'important',\n",
       "  'feature',\n",
       "  'random',\n",
       "  'forest',\n",
       "  'algorithm',\n",
       "  'handle',\n",
       "  'datum',\n",
       "  'setcontaine',\n",
       "  'continuous',\n",
       "  'variable',\n",
       "  'case',\n",
       "  'regression',\n",
       "  'categorical',\n",
       "  'variable',\n",
       "  'case',\n",
       "  'ofclassification',\n",
       "  'perform',\n",
       "  'result',\n",
       "  'classification',\n",
       "  'problem',\n",
       "  'real',\n",
       "  'life',\n",
       "  'analogylet',\n",
       "  'dive',\n",
       "  'real',\n",
       "  'life',\n",
       "  'analogy',\n",
       "  'understand',\n",
       "  'concept',\n",
       "  'far',\n",
       "  'student',\n",
       "  'x',\n",
       "  'want',\n",
       "  'choose',\n",
       "  'acourse',\n",
       "  '10',\n",
       "  '2',\n",
       "  'confused',\n",
       "  'choice',\n",
       "  'course',\n",
       "  'base',\n",
       "  'skill',\n",
       "  'set',\n",
       "  'decidesto',\n",
       "  'consult',\n",
       "  'people',\n",
       "  'like',\n",
       "  'cousin',\n",
       "  'teacher',\n",
       "  'parent',\n",
       "  'degree',\n",
       "  'student',\n",
       "  'work',\n",
       "  'people',\n",
       "  'asksthem',\n",
       "  'varied',\n",
       "  'question',\n",
       "  'like',\n",
       "  'choose',\n",
       "  'job',\n",
       "  'opportunity',\n",
       "  'course',\n",
       "  'course',\n",
       "  'fee',\n",
       "  'etc',\n",
       "  'finally',\n",
       "  'consult',\n",
       "  'people',\n",
       "  'course',\n",
       "  'decide',\n",
       "  'course',\n",
       "  'suggest',\n",
       "  'mostof',\n",
       "  'people',\n",
       "  'work',\n",
       "  'random',\n",
       "  'forest',\n",
       "  'algorithmbefore',\n",
       "  'understand',\n",
       "  'working',\n",
       "  'random',\n",
       "  'forest',\n",
       "  'look',\n",
       "  'ensemble',\n",
       "  'technique',\n",
       "  'ensemble',\n",
       "  'simply',\n",
       "  'mean',\n",
       "  'combine',\n",
       "  'multiple',\n",
       "  'model',\n",
       "  'collection',\n",
       "  'model',\n",
       "  'use',\n",
       "  'makeprediction',\n",
       "  'individual',\n",
       "  'model',\n",
       "  'ensemble',\n",
       "  'use',\n",
       "  'type',\n",
       "  'methods:1',\n",
       "  'bagging',\n",
       "  '–',\n",
       "  'create',\n",
       "  'different',\n",
       "  'training',\n",
       "  'subset',\n",
       "  'sample',\n",
       "  'training',\n",
       "  'datum',\n",
       "  'replacement',\n",
       "  'finaloutput',\n",
       "  'base',\n",
       "  'majority',\n",
       "  'voting',\n",
       "  'example',\n",
       "  'random',\n",
       "  'forest',\n",
       "  'advancedalgorithmclassificationmachine',\n",
       "  'learningprojectpythonregressionstructure',\n",
       "  'datasupervised'],\n",
       " ['2',\n",
       "  'boost',\n",
       "  '–',\n",
       "  'combine',\n",
       "  'weak',\n",
       "  'learner',\n",
       "  'strong',\n",
       "  'learner',\n",
       "  'create',\n",
       "  'sequential',\n",
       "  'model',\n",
       "  'thefinal',\n",
       "  'model',\n",
       "  'high',\n",
       "  'accuracy',\n",
       "  'example',\n",
       "  'ada',\n",
       "  'boost',\n",
       "  'xg',\n",
       "  'boostas',\n",
       "  'mention',\n",
       "  'early',\n",
       "  'random',\n",
       "  'forest',\n",
       "  'work',\n",
       "  'bagging',\n",
       "  'principle',\n",
       "  'let',\n",
       "  'dive',\n",
       "  'understandbagging',\n",
       "  'detail',\n",
       "  'baggingbagging',\n",
       "  'know',\n",
       "  'bootstrap',\n",
       "  'aggregation',\n",
       "  'ensemble',\n",
       "  'technique',\n",
       "  'use',\n",
       "  'random',\n",
       "  'forest',\n",
       "  'baggingchoose',\n",
       "  'random',\n",
       "  'sample',\n",
       "  'datum',\n",
       "  'set',\n",
       "  'model',\n",
       "  'generate',\n",
       "  'sample',\n",
       "  'bootstrapsamples',\n",
       "  'provide',\n",
       "  'original',\n",
       "  'data',\n",
       "  'replacement',\n",
       "  'know',\n",
       "  'row',\n",
       "  'sampling',\n",
       "  'step',\n",
       "  'rowsample',\n",
       "  'replacement',\n",
       "  'bootstrap',\n",
       "  'model',\n",
       "  'train',\n",
       "  'independently',\n",
       "  'generatesresult',\n",
       "  'final',\n",
       "  'output',\n",
       "  'base',\n",
       "  'majority',\n",
       "  'voting',\n",
       "  'combine',\n",
       "  'result',\n",
       "  'model',\n",
       "  'stepwhich',\n",
       "  'involve',\n",
       "  'combine',\n",
       "  'result',\n",
       "  'generate',\n",
       "  'output',\n",
       "  'base',\n",
       "  'majority',\n",
       "  'voting',\n",
       "  'knownas',\n",
       "  'aggregation',\n",
       "  'let',\n",
       "  'look',\n",
       "  'example',\n",
       "  'break',\n",
       "  'help',\n",
       "  'follow',\n",
       "  'figure',\n",
       "  'bootstrapsample',\n",
       "  'actual',\n",
       "  'datum',\n",
       "  'bootstrap',\n",
       "  'sample',\n",
       "  '01',\n",
       "  'bootstrap',\n",
       "  'sample',\n",
       "  '02',\n",
       "  'bootstrap',\n",
       "  'sample',\n",
       "  '03)with',\n",
       "  'replacement',\n",
       "  'mean',\n",
       "  'high',\n",
       "  'possibility',\n",
       "  'sample',\n",
       "  'contain',\n",
       "  'unique',\n",
       "  'datum'],\n",
       " ['model',\n",
       "  'model',\n",
       "  '01',\n",
       "  'model',\n",
       "  '02',\n",
       "  'model',\n",
       "  '03',\n",
       "  'obtain',\n",
       "  'bootstrap',\n",
       "  'sample',\n",
       "  'trainedindependently',\n",
       "  'model',\n",
       "  'generate',\n",
       "  'result',\n",
       "  'happy',\n",
       "  'emoji',\n",
       "  'majority',\n",
       "  'whencompare',\n",
       "  'sad',\n",
       "  'emoji',\n",
       "  'base',\n",
       "  'majority',\n",
       "  'vote',\n",
       "  'final',\n",
       "  'output',\n",
       "  'obtain',\n",
       "  'happy',\n",
       "  'emoji'],\n",
       " ['step',\n",
       "  'involve',\n",
       "  'random',\n",
       "  'forest',\n",
       "  'algorithm',\n",
       "  'step',\n",
       "  '1',\n",
       "  'random',\n",
       "  'forest',\n",
       "  'n',\n",
       "  'number',\n",
       "  'random',\n",
       "  'record',\n",
       "  'datum',\n",
       "  'set',\n",
       "  'k',\n",
       "  'number',\n",
       "  'ofrecord',\n",
       "  'step',\n",
       "  '2',\n",
       "  'individual',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'construct',\n",
       "  'sample',\n",
       "  'step',\n",
       "  '3',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'generate',\n",
       "  'output',\n",
       "  'step',\n",
       "  '4',\n",
       "  'final',\n",
       "  'output',\n",
       "  'consider',\n",
       "  'base',\n",
       "  'majority',\n",
       "  'voting',\n",
       "  'averaging',\n",
       "  'classification',\n",
       "  'regressionrespectively',\n",
       "  'example',\n",
       "  'consider',\n",
       "  'fruit',\n",
       "  'basket',\n",
       "  'datum',\n",
       "  'figure',\n",
       "  'n',\n",
       "  'number',\n",
       "  'samplesare',\n",
       "  'fruit',\n",
       "  'basket',\n",
       "  'individual',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'construct',\n",
       "  'sample',\n",
       "  'eachdecision',\n",
       "  'tree',\n",
       "  'generate',\n",
       "  'output',\n",
       "  'figure',\n",
       "  'final',\n",
       "  'output',\n",
       "  'consider',\n",
       "  'base',\n",
       "  'onmajority',\n",
       "  'voting',\n",
       "  'figure',\n",
       "  'majority',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'output',\n",
       "  'applewhen',\n",
       "  'compare',\n",
       "  'banana',\n",
       "  'final',\n",
       "  'output',\n",
       "  'apple'],\n",
       " ['important',\n",
       "  'features',\n",
       "  'random',\n",
       "  'forest1',\n",
       "  'diversity-',\n",
       "  'attribute',\n",
       "  'variable',\n",
       "  'feature',\n",
       "  'consider',\n",
       "  'individual',\n",
       "  'tree',\n",
       "  'treei',\n",
       "  'different.2',\n",
       "  'immune',\n",
       "  'curse',\n",
       "  'dimensionality-',\n",
       "  'tree',\n",
       "  'consider',\n",
       "  'feature',\n",
       "  'featurespace',\n",
       "  'reduced.3',\n",
       "  'parallelization',\n",
       "  'tree',\n",
       "  'create',\n",
       "  'independently',\n",
       "  'different',\n",
       "  'datum',\n",
       "  'attribute',\n",
       "  'mean',\n",
       "  'thatwe',\n",
       "  'use',\n",
       "  'cpu',\n",
       "  'build',\n",
       "  'random',\n",
       "  'forests.4',\n",
       "  'train',\n",
       "  'test',\n",
       "  'split-',\n",
       "  'random',\n",
       "  'forest',\n",
       "  'segregate',\n",
       "  'datum',\n",
       "  'train',\n",
       "  'test',\n",
       "  'willalway',\n",
       "  '30',\n",
       "  'datum',\n",
       "  'decision',\n",
       "  'tree.5',\n",
       "  'stability-',\n",
       "  'stability',\n",
       "  'arise',\n",
       "  'result',\n",
       "  'base',\n",
       "  'majority',\n",
       "  'voting/',\n",
       "  'averaging',\n",
       "  'difference',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'random',\n",
       "  'forestrandom',\n",
       "  'forest',\n",
       "  'collection',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'lot',\n",
       "  'difference',\n",
       "  'behavior',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'random',\n",
       "  'forest1',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'normally',\n",
       "  'suffer',\n",
       "  'fromthe',\n",
       "  'problem',\n",
       "  'overfitte',\n",
       "  '’',\n",
       "  'allowedto',\n",
       "  'grow',\n",
       "  'control.1',\n",
       "  'random',\n",
       "  'forest',\n",
       "  'create',\n",
       "  'fromsubset',\n",
       "  'datum',\n",
       "  'final',\n",
       "  'output',\n",
       "  'isbase',\n",
       "  'average',\n",
       "  'majority',\n",
       "  'rankingand',\n",
       "  'problem',\n",
       "  'overfitte',\n",
       "  'istaken',\n",
       "  'care',\n",
       "  'of.2',\n",
       "  'single',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'fast',\n",
       "  'incomputation.2',\n",
       "  'comparatively',\n",
       "  'slower.3',\n",
       "  'data',\n",
       "  'set',\n",
       "  'feature',\n",
       "  'istaken',\n",
       "  'input',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'willformulate',\n",
       "  'set',\n",
       "  'rule',\n",
       "  'doprediction.3',\n",
       "  'random',\n",
       "  'forest',\n",
       "  'randomly',\n",
       "  'selectsobservation',\n",
       "  'build',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'andthe',\n",
       "  'average',\n",
       "  'result',\n",
       "  'doesn’tuse',\n",
       "  'set',\n",
       "  'formula',\n",
       "  'random',\n",
       "  'forest',\n",
       "  'successful',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'tree',\n",
       "  'diverse',\n",
       "  'andacceptable',\n",
       "  'important',\n",
       "  'hyperparametershyperparameters',\n",
       "  'use',\n",
       "  'random',\n",
       "  'forest',\n",
       "  'enhance',\n",
       "  'performance',\n",
       "  'predictive',\n",
       "  'power',\n",
       "  'ofmodel',\n",
       "  'model',\n",
       "  'fast',\n",
       "  'follow',\n",
       "  'hyperparameter',\n",
       "  'increase',\n",
       "  'predictive',\n",
       "  'power:1',\n",
       "  'n_estimator',\n",
       "  '–',\n",
       "  'number',\n",
       "  'tree',\n",
       "  'algorithm',\n",
       "  'build',\n",
       "  'average',\n",
       "  'predictions.2',\n",
       "  'max_features',\n",
       "  '–',\n",
       "  'maximum',\n",
       "  'number',\n",
       "  'feature',\n",
       "  'random',\n",
       "  'forest',\n",
       "  'consider',\n",
       "  'split',\n",
       "  'node.3',\n",
       "  'mini_sample_leaf',\n",
       "  '–',\n",
       "  'determine',\n",
       "  'minimum',\n",
       "  'number',\n",
       "  'leave',\n",
       "  'require',\n",
       "  'split',\n",
       "  'internal',\n",
       "  'node',\n",
       "  'follow',\n",
       "  'hyperparameter',\n",
       "  'increase',\n",
       "  'speed:1',\n",
       "  'n_jobs',\n",
       "  '–',\n",
       "  'tell',\n",
       "  'engine',\n",
       "  'processor',\n",
       "  'allow',\n",
       "  'use',\n",
       "  'value',\n",
       "  '1',\n",
       "  'use',\n",
       "  'oneprocessor',\n",
       "  'value',\n",
       "  '-1',\n",
       "  'limit.2',\n",
       "  'random_state',\n",
       "  '–',\n",
       "  'control',\n",
       "  'randomness',\n",
       "  'sample',\n",
       "  'model',\n",
       "  'produce',\n",
       "  'result',\n",
       "  'itha',\n",
       "  'definite',\n",
       "  'value',\n",
       "  'random',\n",
       "  'state',\n",
       "  'hyperparameter',\n",
       "  'sametraine',\n",
       "  'datum'],\n",
       " ['3',\n",
       "  'oob_score',\n",
       "  '–',\n",
       "  'oob',\n",
       "  'mean',\n",
       "  'bag',\n",
       "  'random',\n",
       "  'forest',\n",
       "  'cross',\n",
       "  'validation',\n",
       "  'method',\n",
       "  'thirdof',\n",
       "  'sample',\n",
       "  'use',\n",
       "  'train',\n",
       "  'datum',\n",
       "  'instead',\n",
       "  'use',\n",
       "  'evaluate',\n",
       "  'performance',\n",
       "  'sample',\n",
       "  'arecalle',\n",
       "  'bag',\n",
       "  'sample',\n",
       "  'code',\n",
       "  'python',\n",
       "  '–',\n",
       "  'random',\n",
       "  'forestnow',\n",
       "  'let',\n",
       "  'understand',\n",
       "  'random',\n",
       "  'forest',\n",
       "  'help',\n",
       "  'code.1',\n",
       "  'let',\n",
       "  'import',\n",
       "  'library',\n",
       "  'import',\n",
       "  'require',\n",
       "  'library',\n",
       "  'import',\n",
       "  'panda',\n",
       "  'pd',\n",
       "  'numpy',\n",
       "  'np',\n",
       "  'import',\n",
       "  'matplotlib.pyplot',\n",
       "  'plt',\n",
       "  'seaborna',\n",
       "  'sns',\n",
       "  'matplotlib',\n",
       "  'inline2',\n",
       "  'import',\n",
       "  'dataset',\n",
       "  'read',\n",
       "  'csv',\n",
       "  'file',\n",
       "  'df',\n",
       "  'object',\n",
       "  'df',\n",
       "  \"pd.read_csv('heart_v2.csv\",\n",
       "  'df.head()3',\n",
       "  'feature',\n",
       "  'variable',\n",
       "  'x',\n",
       "  'target',\n",
       "  'variable',\n",
       "  'y.',\n",
       "  'feature',\n",
       "  'variable',\n",
       "  'x',\n",
       "  'x',\n",
       "  \"df.drop('heart\",\n",
       "  \"disease',axis=1\",\n",
       "  'response',\n",
       "  'variable',\n",
       "  'y',\n",
       "  'y',\n",
       "  \"df['heart\",\n",
       "  \"disease']4\",\n",
       "  'train',\n",
       "  'test',\n",
       "  'split',\n",
       "  'perform',\n",
       "  'lets',\n",
       "  'split',\n",
       "  'datum',\n",
       "  'train',\n",
       "  'test',\n",
       "  'sklearn.model_selection',\n",
       "  'import',\n",
       "  'train_test_split',\n",
       "  'split',\n",
       "  'datum',\n",
       "  'train',\n",
       "  'test',\n",
       "  'x_train',\n",
       "  'x_t',\n",
       "  'y_train',\n",
       "  'y_t',\n",
       "  'train_test_split(x',\n",
       "  'y',\n",
       "  'train_size=0.7',\n",
       "  'random_state=42',\n",
       "  'x_train.shape',\n",
       "  'x_test.shape3',\n",
       "  'let',\n",
       "  'import',\n",
       "  'randomforestclassifier',\n",
       "  'fit',\n",
       "  'datum'],\n",
       " ['sklearn.ensemble',\n",
       "  'import',\n",
       "  'randomforestclassifierclassifier_rf',\n",
       "  'randomforestclassifier(random_state=42',\n",
       "  'n_jobs=-1',\n",
       "  'max_depth=5',\n",
       "  'n_estimators=100,oob_score',\n",
       "  'true)%%time',\n",
       "  'classifier_rf.fit(x_train',\n",
       "  'y_train',\n",
       "  'check',\n",
       "  'oob',\n",
       "  'score',\n",
       "  'classifier_rf.oob_score_4',\n",
       "  'let',\n",
       "  'hyperparameter',\n",
       "  'tune',\n",
       "  'random',\n",
       "  'forest',\n",
       "  'use',\n",
       "  'gridsearchcv',\n",
       "  'fit',\n",
       "  'data.rf',\n",
       "  'randomforestclassifier(random_state=42',\n",
       "  'n_jobs=-1)params',\n",
       "  'max_depth',\n",
       "  '2,3,5,10,20',\n",
       "  'min_samples_leaf',\n",
       "  '5,10,20,50,100,200',\n",
       "  \"n_estimators':[10,25,30,50,100,200\",\n",
       "  'sklearn.model_selection',\n",
       "  'import',\n",
       "  'gridsearchcv',\n",
       "  'instantiate',\n",
       "  'grid',\n",
       "  'search',\n",
       "  'model',\n",
       "  'grid_search',\n",
       "  'gridsearchcv(estimator',\n",
       "  'rf',\n",
       "  'param_grid',\n",
       "  'param',\n",
       "  'cv',\n",
       "  '4,n_jobs=-1',\n",
       "  'verbose=1',\n",
       "  'scoring=\"accuracy\")%%time',\n",
       "  'grid_search.fit(x_train',\n",
       "  'y_train)grid_search.best_score'],\n",
       " ['rf_b',\n",
       "  'grid_search.best_estimator',\n",
       "  'rf_bestfrom',\n",
       "  'hyperparameter',\n",
       "  'tuning',\n",
       "  'fetch',\n",
       "  'good',\n",
       "  'estimator',\n",
       "  'good',\n",
       "  'set',\n",
       "  'parametersidentified',\n",
       "  'max_depth=5',\n",
       "  'min_samples_leaf=10,n_estimators=105',\n",
       "  'let',\n",
       "  'visualizefrom',\n",
       "  'sklearn.tree',\n",
       "  'import',\n",
       "  'plot_tree',\n",
       "  'plt.figure(figsize=(80,40',\n",
       "  'plot_tree(rf_best.estimators_[5],feature_name',\n",
       "  'x.columns',\n",
       "  \"class_names=['disease\",\n",
       "  'disease\"],filled',\n",
       "  'true'],\n",
       " ['sklearn.tree',\n",
       "  'import',\n",
       "  'plot_tree',\n",
       "  'plt.figure(figsize=(80,40',\n",
       "  'plot_tree(rf_best.estimators_[7],feature_name',\n",
       "  'x.columns',\n",
       "  \"class_names=['disease\",\n",
       "  'disease\"],filled',\n",
       "  'true'],\n",
       " ['tree',\n",
       "  'create',\n",
       "  'estimators_[5',\n",
       "  'estimators_[7',\n",
       "  'different',\n",
       "  'tree',\n",
       "  'isindependent',\n",
       "  'other.6',\n",
       "  'let',\n",
       "  'sort',\n",
       "  'datum',\n",
       "  'help',\n",
       "  'feature',\n",
       "  'importancerf_best.feature_importance',\n",
       "  'imp_df',\n",
       "  'pd',\n",
       "  'dataframe',\n",
       "  'varname',\n",
       "  'x_train.columns',\n",
       "  'imp',\n",
       "  'rf_best.feature_importance',\n",
       "  'imp_df.sort_values(by=\"imp',\n",
       "  'ascend',\n",
       "  'false',\n",
       "  'use',\n",
       "  'casesthis',\n",
       "  'algorithm',\n",
       "  'widely',\n",
       "  'use',\n",
       "  'e',\n",
       "  'commerce',\n",
       "  'banking',\n",
       "  'medicine',\n",
       "  'stock',\n",
       "  'market',\n",
       "  'etc',\n",
       "  'example',\n",
       "  'banking',\n",
       "  'industry',\n",
       "  'use',\n",
       "  'find',\n",
       "  'customer',\n",
       "  'default',\n",
       "  'loan',\n",
       "  'advantage',\n",
       "  'disadvantages',\n",
       "  'random',\n",
       "  'forest',\n",
       "  'algorithmadvantages'],\n",
       " ['1',\n",
       "  'use',\n",
       "  'classification',\n",
       "  'regression',\n",
       "  'problems.2',\n",
       "  'solve',\n",
       "  'problem',\n",
       "  'overfitting',\n",
       "  'output',\n",
       "  'base',\n",
       "  'majority',\n",
       "  'voting',\n",
       "  'averaging.3',\n",
       "  'perform',\n",
       "  'datum',\n",
       "  'contain',\n",
       "  'null',\n",
       "  'miss',\n",
       "  'values.4',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'create',\n",
       "  'independent',\n",
       "  'property',\n",
       "  'parallelization.5',\n",
       "  'highly',\n",
       "  'stable',\n",
       "  'average',\n",
       "  'answer',\n",
       "  'large',\n",
       "  'number',\n",
       "  'tree',\n",
       "  'taken.6',\n",
       "  'maintain',\n",
       "  'diversity',\n",
       "  'attribute',\n",
       "  'consider',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'itis',\n",
       "  'true',\n",
       "  'cases.7',\n",
       "  'immune',\n",
       "  'curse',\n",
       "  'dimensionality',\n",
       "  'tree',\n",
       "  'consider',\n",
       "  'attribute',\n",
       "  'featurespace',\n",
       "  'reduced.8',\n",
       "  'segregate',\n",
       "  'datum',\n",
       "  'train',\n",
       "  'test',\n",
       "  '30',\n",
       "  'datum',\n",
       "  'notseen',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'bootstrap',\n",
       "  'disadvantages1',\n",
       "  'random',\n",
       "  'forest',\n",
       "  'highly',\n",
       "  'complex',\n",
       "  'compare',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'decision',\n",
       "  'byfollowe',\n",
       "  'path',\n",
       "  'tree.2',\n",
       "  'training',\n",
       "  'time',\n",
       "  'compare',\n",
       "  'model',\n",
       "  'complexity',\n",
       "  'aprediction',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'generate',\n",
       "  'output',\n",
       "  'input',\n",
       "  'datum',\n",
       "  'summarynow',\n",
       "  'conclude',\n",
       "  'random',\n",
       "  'forest',\n",
       "  'good',\n",
       "  'technique',\n",
       "  'high',\n",
       "  'performance',\n",
       "  'iswidely',\n",
       "  'use',\n",
       "  'industry',\n",
       "  'efficiency',\n",
       "  'handle',\n",
       "  'binary',\n",
       "  'continuous',\n",
       "  'categorical',\n",
       "  'datum',\n",
       "  'random',\n",
       "  'forest',\n",
       "  'great',\n",
       "  'choice',\n",
       "  'want',\n",
       "  'build',\n",
       "  'model',\n",
       "  'fast',\n",
       "  'efficiently',\n",
       "  'bestthing',\n",
       "  'random',\n",
       "  'forest',\n",
       "  'handle',\n",
       "  'missing',\n",
       "  'value',\n",
       "  'overall',\n",
       "  'random',\n",
       "  'forest',\n",
       "  'fast',\n",
       "  'simple',\n",
       "  'flexible',\n",
       "  'robust',\n",
       "  'model',\n",
       "  'limitation',\n",
       "  'visit',\n",
       "  'follow',\n",
       "  'link',\n",
       "  'understanding',\n",
       "  'reading!!!i',\n",
       "  'hope',\n",
       "  'enjoy',\n",
       "  'read',\n",
       "  'article',\n",
       "  'increase',\n",
       "  'knowledge',\n",
       "  'random',\n",
       "  'forest',\n",
       "  'mention',\n",
       "  'want',\n",
       "  'share',\n",
       "  'thought',\n",
       "  'feel',\n",
       "  'free',\n",
       "  'comment',\n",
       "  'thecomment',\n",
       "  'section',\n",
       "  'authorsruthi',\n",
       "  'e',\n",
       "  'ri’m',\n",
       "  'data',\n",
       "  'science',\n",
       "  'enthusiast',\n",
       "  'interest',\n",
       "  'datum',\n",
       "  'analysis',\n",
       "  'visualization',\n",
       "  'currently',\n",
       "  'pursue',\n",
       "  'datascience',\n",
       "  'course',\n",
       "  'iiit',\n",
       "  'bangalore',\n",
       "  'come',\n",
       "  'civil',\n",
       "  'engineering',\n",
       "  'background',\n",
       "  '4',\n",
       "  'year',\n",
       "  'experiencein',\n",
       "  'construction',\n",
       "  'industry',\n",
       "  'feel',\n",
       "  'free',\n",
       "  'contact',\n",
       "  'linkedin'],\n",
       " ['medium',\n",
       "  'article',\n",
       "  'analytics',\n",
       "  'vidhya',\n",
       "  'use',\n",
       "  'author’sdiscretion',\n",
       "  'article',\n",
       "  'url']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = df['processed_text'].apply(lambda x: x.split()).tolist()    \n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7a552c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1),\n",
       "  (1, 1),\n",
       "  (2, 1),\n",
       "  (3, 1),\n",
       "  (4, 2),\n",
       "  (5, 1),\n",
       "  (6, 1),\n",
       "  (7, 1),\n",
       "  (8, 1),\n",
       "  (9, 1),\n",
       "  (10, 1),\n",
       "  (11, 1),\n",
       "  (12, 1),\n",
       "  (13, 2),\n",
       "  (14, 1),\n",
       "  (15, 1),\n",
       "  (16, 3),\n",
       "  (17, 1),\n",
       "  (18, 1),\n",
       "  (19, 2),\n",
       "  (20, 2),\n",
       "  (21, 1),\n",
       "  (22, 1),\n",
       "  (23, 1),\n",
       "  (24, 1),\n",
       "  (25, 2),\n",
       "  (26, 1),\n",
       "  (27, 5),\n",
       "  (28, 1),\n",
       "  (29, 1),\n",
       "  (30, 1),\n",
       "  (31, 1),\n",
       "  (32, 2),\n",
       "  (33, 1),\n",
       "  (34, 1),\n",
       "  (35, 1),\n",
       "  (36, 1),\n",
       "  (37, 2),\n",
       "  (38, 1),\n",
       "  (39, 3),\n",
       "  (40, 1),\n",
       "  (41, 1),\n",
       "  (42, 1),\n",
       "  (43, 1),\n",
       "  (44, 1),\n",
       "  (45, 1),\n",
       "  (46, 1),\n",
       "  (47, 1),\n",
       "  (48, 5),\n",
       "  (49, 1),\n",
       "  (50, 1),\n",
       "  (51, 1),\n",
       "  (52, 1),\n",
       "  (53, 1),\n",
       "  (54, 1),\n",
       "  (55, 1),\n",
       "  (56, 2),\n",
       "  (57, 2),\n",
       "  (58, 1),\n",
       "  (59, 1),\n",
       "  (60, 2),\n",
       "  (61, 1),\n",
       "  (62, 1),\n",
       "  (63, 1),\n",
       "  (64, 3),\n",
       "  (65, 1),\n",
       "  (66, 1),\n",
       "  (67, 1),\n",
       "  (68, 1),\n",
       "  (69, 1),\n",
       "  (70, 4),\n",
       "  (71, 1),\n",
       "  (72, 2),\n",
       "  (73, 1),\n",
       "  (74, 1),\n",
       "  (75, 5),\n",
       "  (76, 2),\n",
       "  (77, 2),\n",
       "  (78, 1),\n",
       "  (79, 1),\n",
       "  (80, 2),\n",
       "  (81, 1),\n",
       "  (82, 1),\n",
       "  (83, 1),\n",
       "  (84, 1),\n",
       "  (85, 1),\n",
       "  (86, 2),\n",
       "  (87, 1),\n",
       "  (88, 1),\n",
       "  (89, 1),\n",
       "  (90, 1),\n",
       "  (91, 1),\n",
       "  (92, 2),\n",
       "  (93, 1),\n",
       "  (94, 1),\n",
       "  (95, 3),\n",
       "  (96, 3),\n",
       "  (97, 2),\n",
       "  (98, 1),\n",
       "  (99, 1),\n",
       "  (100, 1),\n",
       "  (101, 1),\n",
       "  (102, 1),\n",
       "  (103, 2),\n",
       "  (104, 1),\n",
       "  (105, 1),\n",
       "  (106, 1)],\n",
       " [(1, 1),\n",
       "  (12, 1),\n",
       "  (13, 2),\n",
       "  (22, 3),\n",
       "  (29, 1),\n",
       "  (30, 1),\n",
       "  (32, 3),\n",
       "  (38, 1),\n",
       "  (39, 1),\n",
       "  (41, 2),\n",
       "  (48, 2),\n",
       "  (58, 1),\n",
       "  (60, 2),\n",
       "  (62, 1),\n",
       "  (64, 5),\n",
       "  (75, 3),\n",
       "  (78, 3),\n",
       "  (79, 2),\n",
       "  (80, 6),\n",
       "  (82, 1),\n",
       "  (91, 1),\n",
       "  (96, 1),\n",
       "  (100, 2),\n",
       "  (103, 1),\n",
       "  (106, 1),\n",
       "  (107, 1),\n",
       "  (108, 1),\n",
       "  (109, 1),\n",
       "  (110, 1),\n",
       "  (111, 1),\n",
       "  (112, 1),\n",
       "  (113, 2),\n",
       "  (114, 1),\n",
       "  (115, 1),\n",
       "  (116, 2),\n",
       "  (117, 1),\n",
       "  (118, 5),\n",
       "  (119, 1),\n",
       "  (120, 1),\n",
       "  (121, 1),\n",
       "  (122, 1),\n",
       "  (123, 1),\n",
       "  (124, 1),\n",
       "  (125, 1),\n",
       "  (126, 1),\n",
       "  (127, 1),\n",
       "  (128, 2),\n",
       "  (129, 1),\n",
       "  (130, 1),\n",
       "  (131, 2),\n",
       "  (132, 1),\n",
       "  (133, 1),\n",
       "  (134, 2),\n",
       "  (135, 1),\n",
       "  (136, 2),\n",
       "  (137, 2),\n",
       "  (138, 1),\n",
       "  (139, 1),\n",
       "  (140, 2),\n",
       "  (141, 1),\n",
       "  (142, 1),\n",
       "  (143, 1),\n",
       "  (144, 1),\n",
       "  (145, 1),\n",
       "  (146, 1),\n",
       "  (147, 1),\n",
       "  (148, 1),\n",
       "  (149, 1),\n",
       "  (150, 1),\n",
       "  (151, 1),\n",
       "  (152, 1),\n",
       "  (153, 1),\n",
       "  (154, 1),\n",
       "  (155, 1),\n",
       "  (156, 1)],\n",
       " [(13, 1),\n",
       "  (60, 2),\n",
       "  (64, 5),\n",
       "  (79, 1),\n",
       "  (80, 1),\n",
       "  (99, 1),\n",
       "  (107, 1),\n",
       "  (108, 1),\n",
       "  (118, 1),\n",
       "  (126, 1),\n",
       "  (128, 1),\n",
       "  (140, 1),\n",
       "  (157, 1),\n",
       "  (158, 3),\n",
       "  (159, 2),\n",
       "  (160, 2),\n",
       "  (161, 1),\n",
       "  (162, 1),\n",
       "  (163, 1)],\n",
       " [(1, 1),\n",
       "  (4, 1),\n",
       "  (13, 2),\n",
       "  (20, 1),\n",
       "  (32, 2),\n",
       "  (35, 4),\n",
       "  (41, 1),\n",
       "  (48, 2),\n",
       "  (52, 2),\n",
       "  (60, 2),\n",
       "  (75, 3),\n",
       "  (80, 2),\n",
       "  (82, 1),\n",
       "  (93, 5),\n",
       "  (100, 2),\n",
       "  (125, 3),\n",
       "  (126, 3),\n",
       "  (128, 2),\n",
       "  (133, 1),\n",
       "  (140, 6),\n",
       "  (148, 5),\n",
       "  (164, 1),\n",
       "  (165, 1),\n",
       "  (166, 1),\n",
       "  (167, 1),\n",
       "  (168, 1),\n",
       "  (169, 1),\n",
       "  (170, 1),\n",
       "  (171, 2),\n",
       "  (172, 1),\n",
       "  (173, 3),\n",
       "  (174, 2),\n",
       "  (175, 1),\n",
       "  (176, 2),\n",
       "  (177, 1),\n",
       "  (178, 2),\n",
       "  (179, 3),\n",
       "  (180, 1),\n",
       "  (181, 1),\n",
       "  (182, 1),\n",
       "  (183, 1),\n",
       "  (184, 1)],\n",
       " [(4, 1),\n",
       "  (11, 3),\n",
       "  (13, 1),\n",
       "  (15, 3),\n",
       "  (21, 1),\n",
       "  (29, 2),\n",
       "  (30, 1),\n",
       "  (32, 5),\n",
       "  (35, 9),\n",
       "  (37, 1),\n",
       "  (43, 4),\n",
       "  (48, 7),\n",
       "  (51, 2),\n",
       "  (52, 1),\n",
       "  (60, 2),\n",
       "  (62, 1),\n",
       "  (64, 2),\n",
       "  (72, 2),\n",
       "  (75, 11),\n",
       "  (79, 3),\n",
       "  (80, 1),\n",
       "  (82, 3),\n",
       "  (93, 13),\n",
       "  (96, 4),\n",
       "  (97, 1),\n",
       "  (106, 5),\n",
       "  (126, 1),\n",
       "  (127, 2),\n",
       "  (132, 1),\n",
       "  (140, 1),\n",
       "  (152, 2),\n",
       "  (164, 1),\n",
       "  (169, 1),\n",
       "  (173, 3),\n",
       "  (179, 3),\n",
       "  (185, 1),\n",
       "  (186, 1),\n",
       "  (187, 1),\n",
       "  (188, 1),\n",
       "  (189, 1),\n",
       "  (190, 1),\n",
       "  (191, 1),\n",
       "  (192, 2),\n",
       "  (193, 1),\n",
       "  (194, 1),\n",
       "  (195, 1),\n",
       "  (196, 1),\n",
       "  (197, 1),\n",
       "  (198, 1),\n",
       "  (199, 1),\n",
       "  (200, 1),\n",
       "  (201, 1),\n",
       "  (202, 2),\n",
       "  (203, 1),\n",
       "  (204, 1),\n",
       "  (205, 1),\n",
       "  (206, 1),\n",
       "  (207, 1),\n",
       "  (208, 1),\n",
       "  (209, 1),\n",
       "  (210, 1),\n",
       "  (211, 2),\n",
       "  (212, 1),\n",
       "  (213, 1),\n",
       "  (214, 2),\n",
       "  (215, 1),\n",
       "  (216, 1),\n",
       "  (217, 1),\n",
       "  (218, 1),\n",
       "  (219, 1),\n",
       "  (220, 1),\n",
       "  (221, 3),\n",
       "  (222, 1),\n",
       "  (223, 1),\n",
       "  (224, 1),\n",
       "  (225, 2),\n",
       "  (226, 1),\n",
       "  (227, 1),\n",
       "  (228, 1),\n",
       "  (229, 2),\n",
       "  (230, 1),\n",
       "  (231, 1),\n",
       "  (232, 1),\n",
       "  (233, 1),\n",
       "  (234, 1),\n",
       "  (235, 1),\n",
       "  (236, 1),\n",
       "  (237, 1),\n",
       "  (238, 1),\n",
       "  (239, 1),\n",
       "  (240, 1),\n",
       "  (241, 1),\n",
       "  (242, 1),\n",
       "  (243, 1),\n",
       "  (244, 1),\n",
       "  (245, 1),\n",
       "  (246, 2),\n",
       "  (247, 1),\n",
       "  (248, 1),\n",
       "  (249, 1),\n",
       "  (250, 1),\n",
       "  (251, 1),\n",
       "  (252, 2),\n",
       "  (253, 1),\n",
       "  (254, 1),\n",
       "  (255, 1),\n",
       "  (256, 1),\n",
       "  (257, 1),\n",
       "  (258, 1),\n",
       "  (259, 1),\n",
       "  (260, 1),\n",
       "  (261, 1),\n",
       "  (262, 1),\n",
       "  (263, 1),\n",
       "  (264, 1),\n",
       "  (265, 1),\n",
       "  (266, 1),\n",
       "  (267, 1),\n",
       "  (268, 2),\n",
       "  (269, 1),\n",
       "  (270, 1),\n",
       "  (271, 1),\n",
       "  (272, 1),\n",
       "  (273, 1),\n",
       "  (274, 1),\n",
       "  (275, 1),\n",
       "  (276, 2),\n",
       "  (277, 1),\n",
       "  (278, 1),\n",
       "  (279, 1),\n",
       "  (280, 3),\n",
       "  (281, 1),\n",
       "  (282, 1),\n",
       "  (283, 1),\n",
       "  (284, 1)],\n",
       " [(32, 4),\n",
       "  (43, 2),\n",
       "  (48, 2),\n",
       "  (62, 1),\n",
       "  (71, 1),\n",
       "  (75, 3),\n",
       "  (80, 3),\n",
       "  (95, 1),\n",
       "  (96, 2),\n",
       "  (97, 4),\n",
       "  (105, 3),\n",
       "  (106, 2),\n",
       "  (130, 1),\n",
       "  (137, 3),\n",
       "  (152, 4),\n",
       "  (165, 1),\n",
       "  (248, 1),\n",
       "  (260, 1),\n",
       "  (268, 3),\n",
       "  (276, 3),\n",
       "  (285, 1),\n",
       "  (286, 2),\n",
       "  (287, 1),\n",
       "  (288, 1),\n",
       "  (289, 1),\n",
       "  (290, 1),\n",
       "  (291, 1),\n",
       "  (292, 2),\n",
       "  (293, 1),\n",
       "  (294, 1),\n",
       "  (295, 1),\n",
       "  (296, 1),\n",
       "  (297, 1),\n",
       "  (298, 1),\n",
       "  (299, 1),\n",
       "  (300, 1),\n",
       "  (301, 1),\n",
       "  (302, 7),\n",
       "  (303, 1),\n",
       "  (304, 1),\n",
       "  (305, 1),\n",
       "  (306, 2),\n",
       "  (307, 1),\n",
       "  (308, 1),\n",
       "  (309, 1),\n",
       "  (310, 1),\n",
       "  (311, 1),\n",
       "  (312, 1),\n",
       "  (313, 1),\n",
       "  (314, 1),\n",
       "  (315, 1),\n",
       "  (316, 1),\n",
       "  (317, 1),\n",
       "  (318, 1),\n",
       "  (319, 1),\n",
       "  (320, 1),\n",
       "  (321, 1),\n",
       "  (322, 1),\n",
       "  (323, 1),\n",
       "  (324, 1),\n",
       "  (325, 1),\n",
       "  (326, 1),\n",
       "  (327, 1),\n",
       "  (328, 1),\n",
       "  (329, 1),\n",
       "  (330, 1),\n",
       "  (331, 1),\n",
       "  (332, 1),\n",
       "  (333, 1),\n",
       "  (334, 1),\n",
       "  (335, 1),\n",
       "  (336, 1),\n",
       "  (337, 3),\n",
       "  (338, 1),\n",
       "  (339, 1),\n",
       "  (340, 1)],\n",
       " [(48, 1),\n",
       "  (64, 1),\n",
       "  (75, 1),\n",
       "  (96, 1),\n",
       "  (137, 1),\n",
       "  (221, 1),\n",
       "  (300, 1),\n",
       "  (302, 2),\n",
       "  (313, 1),\n",
       "  (325, 1),\n",
       "  (340, 1),\n",
       "  (341, 1),\n",
       "  (342, 1),\n",
       "  (343, 1),\n",
       "  (344, 1),\n",
       "  (345, 1),\n",
       "  (346, 1),\n",
       "  (347, 1),\n",
       "  (348, 1),\n",
       "  (349, 1),\n",
       "  (350, 1),\n",
       "  (351, 1),\n",
       "  (352, 2),\n",
       "  (353, 1),\n",
       "  (354, 1),\n",
       "  (355, 1),\n",
       "  (356, 1),\n",
       "  (357, 1),\n",
       "  (358, 1),\n",
       "  (359, 1),\n",
       "  (360, 1),\n",
       "  (361, 1),\n",
       "  (362, 1),\n",
       "  (363, 1),\n",
       "  (364, 2),\n",
       "  (365, 1),\n",
       "  (366, 1),\n",
       "  (367, 1),\n",
       "  (368, 1),\n",
       "  (369, 1),\n",
       "  (370, 1),\n",
       "  (371, 1),\n",
       "  (372, 1),\n",
       "  (373, 1),\n",
       "  (374, 1)],\n",
       " [(82, 1),\n",
       "  (137, 1),\n",
       "  (221, 1),\n",
       "  (302, 1),\n",
       "  (356, 1),\n",
       "  (375, 1),\n",
       "  (376, 1),\n",
       "  (377, 1),\n",
       "  (378, 1),\n",
       "  (379, 2),\n",
       "  (380, 1),\n",
       "  (381, 1),\n",
       "  (382, 1),\n",
       "  (383, 1),\n",
       "  (384, 1),\n",
       "  (385, 1),\n",
       "  (386, 1),\n",
       "  (387, 1),\n",
       "  (388, 1),\n",
       "  (389, 1),\n",
       "  (390, 1),\n",
       "  (391, 1),\n",
       "  (392, 1)],\n",
       " [(302, 1),\n",
       "  (375, 1),\n",
       "  (376, 1),\n",
       "  (383, 1),\n",
       "  (385, 1),\n",
       "  (388, 1),\n",
       "  (389, 1),\n",
       "  (392, 1),\n",
       "  (393, 1)],\n",
       " [(4, 1),\n",
       "  (29, 1),\n",
       "  (32, 1),\n",
       "  (37, 1),\n",
       "  (40, 1),\n",
       "  (41, 1),\n",
       "  (43, 1),\n",
       "  (48, 1),\n",
       "  (75, 1),\n",
       "  (93, 2),\n",
       "  (96, 3),\n",
       "  (102, 1),\n",
       "  (130, 1),\n",
       "  (137, 1),\n",
       "  (316, 1),\n",
       "  (394, 1),\n",
       "  (395, 1),\n",
       "  (396, 1),\n",
       "  (397, 2),\n",
       "  (398, 1),\n",
       "  (399, 1),\n",
       "  (400, 1),\n",
       "  (401, 1),\n",
       "  (402, 1),\n",
       "  (403, 1),\n",
       "  (404, 1),\n",
       "  (405, 1),\n",
       "  (406, 1),\n",
       "  (407, 1),\n",
       "  (408, 1),\n",
       "  (409, 1),\n",
       "  (410, 1),\n",
       "  (411, 1),\n",
       "  (412, 1),\n",
       "  (413, 1),\n",
       "  (414, 1),\n",
       "  (415, 1),\n",
       "  (416, 1),\n",
       "  (417, 1),\n",
       "  (418, 1),\n",
       "  (419, 1),\n",
       "  (420, 1),\n",
       "  (421, 1),\n",
       "  (422, 1),\n",
       "  (423, 1)],\n",
       " [(9, 1),\n",
       "  (11, 1),\n",
       "  (13, 1),\n",
       "  (15, 1),\n",
       "  (17, 1),\n",
       "  (18, 1),\n",
       "  (20, 1),\n",
       "  (26, 1),\n",
       "  (27, 1),\n",
       "  (29, 1),\n",
       "  (30, 1),\n",
       "  (32, 6),\n",
       "  (35, 6),\n",
       "  (48, 6),\n",
       "  (50, 2),\n",
       "  (60, 1),\n",
       "  (64, 3),\n",
       "  (71, 1),\n",
       "  (72, 1),\n",
       "  (75, 6),\n",
       "  (77, 1),\n",
       "  (81, 1),\n",
       "  (91, 1),\n",
       "  (92, 1),\n",
       "  (93, 7),\n",
       "  (96, 2),\n",
       "  (100, 1),\n",
       "  (101, 2),\n",
       "  (118, 1),\n",
       "  (122, 1),\n",
       "  (127, 1),\n",
       "  (128, 1),\n",
       "  (131, 1),\n",
       "  (138, 1),\n",
       "  (140, 2),\n",
       "  (152, 1),\n",
       "  (164, 1),\n",
       "  (166, 1),\n",
       "  (172, 2),\n",
       "  (173, 2),\n",
       "  (179, 1),\n",
       "  (186, 1),\n",
       "  (192, 2),\n",
       "  (199, 1),\n",
       "  (211, 2),\n",
       "  (213, 1),\n",
       "  (223, 1),\n",
       "  (225, 1),\n",
       "  (226, 1),\n",
       "  (248, 1),\n",
       "  (263, 1),\n",
       "  (276, 1),\n",
       "  (280, 1),\n",
       "  (322, 1),\n",
       "  (379, 1),\n",
       "  (389, 1),\n",
       "  (404, 1),\n",
       "  (413, 2),\n",
       "  (424, 1),\n",
       "  (425, 1),\n",
       "  (426, 1),\n",
       "  (427, 1),\n",
       "  (428, 1),\n",
       "  (429, 1),\n",
       "  (430, 1),\n",
       "  (431, 1),\n",
       "  (432, 1),\n",
       "  (433, 1),\n",
       "  (434, 1),\n",
       "  (435, 1),\n",
       "  (436, 1),\n",
       "  (437, 1),\n",
       "  (438, 1),\n",
       "  (439, 1),\n",
       "  (440, 1),\n",
       "  (441, 1),\n",
       "  (442, 1),\n",
       "  (443, 1),\n",
       "  (444, 1),\n",
       "  (445, 1),\n",
       "  (446, 1),\n",
       "  (447, 1),\n",
       "  (448, 1),\n",
       "  (449, 1),\n",
       "  (450, 1),\n",
       "  (451, 1),\n",
       "  (452, 1),\n",
       "  (453, 1),\n",
       "  (454, 2),\n",
       "  (455, 1),\n",
       "  (456, 2),\n",
       "  (457, 1),\n",
       "  (458, 2),\n",
       "  (459, 1),\n",
       "  (460, 1),\n",
       "  (461, 1),\n",
       "  (462, 1),\n",
       "  (463, 1),\n",
       "  (464, 1),\n",
       "  (465, 1),\n",
       "  (466, 1),\n",
       "  (467, 1),\n",
       "  (468, 1),\n",
       "  (469, 1),\n",
       "  (470, 1),\n",
       "  (471, 1),\n",
       "  (472, 1),\n",
       "  (473, 1),\n",
       "  (474, 1),\n",
       "  (475, 1),\n",
       "  (476, 1),\n",
       "  (477, 1),\n",
       "  (478, 1),\n",
       "  (479, 1),\n",
       "  (480, 1),\n",
       "  (481, 1),\n",
       "  (482, 1),\n",
       "  (483, 1),\n",
       "  (484, 1),\n",
       "  (485, 1),\n",
       "  (486, 1),\n",
       "  (487, 1),\n",
       "  (488, 1),\n",
       "  (489, 1),\n",
       "  (490, 1),\n",
       "  (491, 1),\n",
       "  (492, 1),\n",
       "  (493, 1),\n",
       "  (494, 1),\n",
       "  (495, 1),\n",
       "  (496, 1),\n",
       "  (497, 1),\n",
       "  (498, 1),\n",
       "  (499, 1),\n",
       "  (500, 1),\n",
       "  (501, 1)],\n",
       " [(9, 2), (96, 1), (502, 1), (503, 1), (504, 1), (505, 1), (506, 1)]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(documents)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in documents]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "160b0ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('case', 0.24939118224988546),\n",
       "  ('course', 0.29970878542280766),\n",
       "  ('people', 0.3325215763331806)],\n",
       " [('combine', 0.23639560580249785),\n",
       "  ('replacement', 0.23639560580249785),\n",
       "  ('aggregation', 0.21856393968340285),\n",
       "  ('boost', 0.21856393968340285),\n",
       "  ('bootstrap', 0.3048343457420213),\n",
       "  ('know', 0.21856393968340285),\n",
       "  ('learner', 0.21856393968340285)],\n",
       " [('model', 0.27355967595212805),\n",
       "  ('emoji', 0.5884207079986862),\n",
       "  ('happy', 0.3922804719991241),\n",
       "  ('obtain', 0.3922804719991241)],\n",
       " [('decision', 0.21127590791103987),\n",
       "  ('tree', 0.2104535128544048),\n",
       "  ('figure', 0.25843212331870363),\n",
       "  ('output', 0.25254421542528577),\n",
       "  ('step', 0.4307202055311727),\n",
       "  ('basket', 0.23893821046941827),\n",
       "  ('construct', 0.23893821046941827),\n",
       "  ('fruit', 0.23893821046941827),\n",
       "  ('n', 0.23893821046941827)],\n",
       " [('decision', 0.28395207820677065), ('tree', 0.32684517946777325)],\n",
       " [('variable', 0.21650194078258567),\n",
       "  ('x', 0.2098685243461261),\n",
       "  ('split', 0.2098685243461261),\n",
       "  ('import', 0.3002540252895318),\n",
       "  ('y', 0.29105675213959575)],\n",
       " [('gridsearchcv', 0.30508753882384465),\n",
       "  ('randomforestclassifier(random_state=42', 0.30508753882384465)],\n",
       " [('estimator', 0.24408149790403041),\n",
       "  ('fetch', 0.24408149790403041),\n",
       "  ('good', 0.35199337179948015),\n",
       "  ('grid_search.best_estimator', 0.24408149790403041),\n",
       "  ('min_samples_leaf=10,n_estimators=105', 0.24408149790403041),\n",
       "  ('parametersidentified', 0.24408149790403041),\n",
       "  ('plot_tree(rf_best.estimators_[5],feature_name', 0.24408149790403041),\n",
       "  ('rf_b', 0.24408149790403041),\n",
       "  ('rf_bestfrom', 0.24408149790403041),\n",
       "  ('tuning', 0.24408149790403041),\n",
       "  ('visualizefrom', 0.24408149790403041)],\n",
       " [('import', 0.2055513048179479),\n",
       "  (\"class_names=['disease\", 0.3352397389130273),\n",
       "  ('disease\"],filled', 0.3352397389130273),\n",
       "  ('plot_tree', 0.3352397389130273),\n",
       "  ('plt.figure(figsize=(80,40', 0.3352397389130273),\n",
       "  ('sklearn.tree', 0.3352397389130273),\n",
       "  ('true', 0.25937686819015876),\n",
       "  ('x.columns', 0.3352397389130273),\n",
       "  ('plot_tree(rf_best.estimators_[7],feature_name', 0.4649281730081067)],\n",
       " [('banking', 0.33382906745928353)],\n",
       " [('decision', 0.22778994175742093), ('tree', 0.21177638117422828)],\n",
       " [('article', 0.4455404972113978),\n",
       "  ('analytics', 0.39931149376388003),\n",
       "  ('author’sdiscretion', 0.39931149376388003),\n",
       "  ('medium', 0.39931149376388003),\n",
       "  ('url', 0.39931149376388003),\n",
       "  ('vidhya', 0.39931149376388003)]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform keyword extraction using TF-IDF\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "\n",
    "keyword_threshold = 0.2\n",
    "keywords = []\n",
    "\n",
    "for doc in corpus:\n",
    "    doc_tfidf = tfidf[doc]\n",
    "    doc_keywords = [(dictionary[word_id], tfidf_value) for word_id, tfidf_value in doc_tfidf if tfidf_value > keyword_threshold]\n",
    "    keywords.append(doc_keywords)\n",
    "    \n",
    "keywords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef359d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 keywords:\n",
      "case - 0.24939118224988546\n",
      "course - 0.29970878542280766\n",
      "people - 0.3325215763331806\n",
      "-------------------------------------\n",
      "Document 2 keywords:\n",
      "combine - 0.23639560580249785\n",
      "replacement - 0.23639560580249785\n",
      "aggregation - 0.21856393968340285\n",
      "boost - 0.21856393968340285\n",
      "bootstrap - 0.3048343457420213\n",
      "know - 0.21856393968340285\n",
      "learner - 0.21856393968340285\n",
      "-------------------------------------\n",
      "Document 3 keywords:\n",
      "model - 0.27355967595212805\n",
      "emoji - 0.5884207079986862\n",
      "happy - 0.3922804719991241\n",
      "obtain - 0.3922804719991241\n",
      "-------------------------------------\n",
      "Document 4 keywords:\n",
      "decision - 0.21127590791103987\n",
      "tree - 0.2104535128544048\n",
      "figure - 0.25843212331870363\n",
      "output - 0.25254421542528577\n",
      "step - 0.4307202055311727\n",
      "basket - 0.23893821046941827\n",
      "construct - 0.23893821046941827\n",
      "fruit - 0.23893821046941827\n",
      "n - 0.23893821046941827\n",
      "-------------------------------------\n",
      "Document 5 keywords:\n",
      "decision - 0.28395207820677065\n",
      "tree - 0.32684517946777325\n",
      "-------------------------------------\n",
      "Document 6 keywords:\n",
      "variable - 0.21650194078258567\n",
      "x - 0.2098685243461261\n",
      "split - 0.2098685243461261\n",
      "import - 0.3002540252895318\n",
      "y - 0.29105675213959575\n",
      "-------------------------------------\n",
      "Document 7 keywords:\n",
      "gridsearchcv - 0.30508753882384465\n",
      "randomforestclassifier(random_state=42 - 0.30508753882384465\n",
      "-------------------------------------\n",
      "Document 8 keywords:\n",
      "estimator - 0.24408149790403041\n",
      "fetch - 0.24408149790403041\n",
      "good - 0.35199337179948015\n",
      "grid_search.best_estimator - 0.24408149790403041\n",
      "min_samples_leaf=10,n_estimators=105 - 0.24408149790403041\n",
      "parametersidentified - 0.24408149790403041\n",
      "plot_tree(rf_best.estimators_[5],feature_name - 0.24408149790403041\n",
      "rf_b - 0.24408149790403041\n",
      "rf_bestfrom - 0.24408149790403041\n",
      "tuning - 0.24408149790403041\n",
      "visualizefrom - 0.24408149790403041\n",
      "-------------------------------------\n",
      "Document 9 keywords:\n",
      "import - 0.2055513048179479\n",
      "class_names=['disease - 0.3352397389130273\n",
      "disease\"],filled - 0.3352397389130273\n",
      "plot_tree - 0.3352397389130273\n",
      "plt.figure(figsize=(80,40 - 0.3352397389130273\n",
      "sklearn.tree - 0.3352397389130273\n",
      "true - 0.25937686819015876\n",
      "x.columns - 0.3352397389130273\n",
      "plot_tree(rf_best.estimators_[7],feature_name - 0.4649281730081067\n",
      "-------------------------------------\n",
      "Document 10 keywords:\n",
      "banking - 0.33382906745928353\n",
      "-------------------------------------\n",
      "Document 11 keywords:\n",
      "decision - 0.22778994175742093\n",
      "tree - 0.21177638117422828\n",
      "-------------------------------------\n",
      "Document 12 keywords:\n",
      "article - 0.4455404972113978\n",
      "analytics - 0.39931149376388003\n",
      "author’sdiscretion - 0.39931149376388003\n",
      "medium - 0.39931149376388003\n",
      "url - 0.39931149376388003\n",
      "vidhya - 0.39931149376388003\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for idx, doc_keywords in enumerate(keywords):\n",
    "    print(f\"Document {idx+1} keywords:\")\n",
    "    \n",
    "    for keyword, tfidf_value in doc_keywords:\n",
    "        print(keyword, \"-\", tfidf_value)\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0a050b",
   "metadata": {},
   "source": [
    "### Topic modeling using Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d655d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Topics:-\n",
      "\n",
      "Topic 1:\n",
      "import - 0.032486834\n",
      "use - 0.018063974\n",
      "let - 0.018037416\n",
      "random - 0.015177302\n",
      "datum - 0.015157547\n",
      "forest - 0.0122818565\n",
      "variable - 0.012209837\n",
      "train - 0.0122062275\n",
      "feature - 0.009333784\n",
      "sample - 0.009323869\n",
      "-------------------------------------\n",
      "Topic 2:\n",
      "sample - 0.029253094\n",
      "bootstrap - 0.024488205\n",
      "model - 0.02448809\n",
      "random - 0.01514961\n",
      "datum - 0.015113642\n",
      "combine - 0.015078198\n",
      "replacement - 0.015063466\n",
      "forest - 0.010438185\n",
      "output - 0.010421505\n",
      "majority - 0.010404459\n",
      "-------------------------------------\n",
      "Topic 3:\n",
      "random - 0.020195553\n",
      "forest - 0.020065168\n",
      "course - 0.01990265\n",
      "use - 0.016189571\n",
      "people - 0.016059281\n",
      "model - 0.012311964\n",
      "article - 0.012288909\n",
      "understand - 0.012254553\n",
      "case - 0.012240262\n",
      "ensemble - 0.012239718\n",
      "-------------------------------------\n",
      "Topic 4:\n",
      "tree - 0.03848133\n",
      "random - 0.032764364\n",
      "decision - 0.028963197\n",
      "forest - 0.025160909\n",
      "datum - 0.021384787\n",
      "model - 0.019505922\n",
      "use - 0.0118291285\n",
      "majority - 0.009939866\n",
      "– - 0.009908254\n",
      "consider - 0.009899174\n",
      "-------------------------------------\n",
      "Topic 5:\n",
      "output - 0.034018025\n",
      "tree - 0.028533094\n",
      "step - 0.028513342\n",
      "decision - 0.023065342\n",
      "random - 0.01765371\n",
      "final - 0.01756361\n",
      "consider - 0.017554939\n",
      "figure - 0.01754646\n",
      "number - 0.017544642\n",
      "sample - 0.01213629\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "required_num_topics = 5\n",
    "lda_model = models.LdaModel(corpus, num_topics=required_num_topics, id2word=dictionary, passes=10)\n",
    "\n",
    "print(\"LDA Topics:-\\n\")\n",
    "\n",
    "for idx in range(required_num_topics):\n",
    "    print(f\"Topic {idx+1}:\")\n",
    "    topic_keywords = lda_model.show_topic(idx)\n",
    "    \n",
    "    for keyword, prob in topic_keywords:\n",
    "        print(keyword, \"-\", prob)\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e085b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score: 0.4479193717421756\n"
     ]
    }
   ],
   "source": [
    "# Coherence score for the LDA model\n",
    "\n",
    "coherence_model = CoherenceModel(model=lda_model, texts=documents, dictionary=dictionary, coherence='c_v')\n",
    "coherence_score = coherence_model.get_coherence()\n",
    "print(\"Coherence Score:\", coherence_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
